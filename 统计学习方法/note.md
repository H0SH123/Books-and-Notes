# 统计学习方法

## 第一章 统计学习及监督学习概论

### 1.2 统计学习的分类

#### 基本分类

##### 监督学习

**监督学习（supervised learning）** 是指从标注数据中学习预测模型的机器学习问题。标注数据表示输入输出的对应关系，预测模型对给定的输入产生相应的输出。

监督学习的本质是学习输入到输出的映射的统计规律。

**输入空间、特征空间和输出空间**

在监督学习中，将输入与输出所有可能取值的集合分别称为**输入空间 (input space) 与输出空间 (output space)** 。

通常输出空间远远小于输入空间。

每个具体的输入是一个**实例(instance)** ，通常由**特征向量 (feature vector)** 表示。

所有特征向量存在的空间称为**特征空间 (feature space)** 。

**输入与输出**是定义在输入（特征）空间与输出空间上的随机变量的取值。输入变量写作 $X$，输出变量写作 $Y$。输入变量的取值写作 $x$，输出变量的取值写作 $y$ 。

输出示例 $x$ 的特征向量记作：


$$
x = \begin{pmatrix}
x^{(1)}, x^{(2)}, \cdots, x^{(i)}, \cdots, x^{(n)}
\end{pmatrix}^\mathrm{T}
$$

- $x^{(i)}$ 表示 $x$ 的第 $i$ 个特征

$$
x_i = \begin{pmatrix}
x_i^{(1)}, x_i^{(2)}, \cdots, x_i^{(n)}
\end{pmatrix}^\mathrm{T}
$$

-  $x_i$ 表示多个输入变量中的第 $i$ 个变量

监督学习从**训练数据（training data）** 集合中学习模型，对**测试数据（test data）**进行预测。训练数据由输入（或特征向量）与输出对组成，训练集通常表示为：

$$
T = \{(x_1, y_1), (x_2, y_2), \cdots, (x_N, y_N)\}
$$

测试数据也由输入与输出对组成。输入与输出对又称为 **样本 (sample)** 或样本点。

输入变量 $X$ 和输出变量 $Y$ 有不同的类型：

- 输入变量与输出变量均为连续变量的预测问题称为回归问题
- 输出变量为有限个离散变量的预测问题称为分类问题
- 输入变量与输出变量均为变量序列的预测问题称为标注问题

**联合概率分布**

监督学习假设输入与输出的随机变量 $X$ 和 $Y$ 遵循联合概率分布 $P(X, Y)$。$P(X, Y)$ 表示分布函数，或分布密度函数。

训练数据与测试数据被看作是依据联合概率分布 $P(X, Y)$ 独立同分布产生的。

**假设空间**

监督学习的目的在于学习一个由输入到输出的映射，这一映射由模型来表示。模型属于由输入空间到输出空间 的映射的集合，这个集合就是**假设空间 (hypothesis space)** 。

监督学习的模型

- 概率模型：由条件概率分布 $P(Y|X)$ 表示，写作 $P(y|x)$ 。
- 非概率模型：由**决策函数（decision function）**$Y = f(X)$ 表示，写作 $y = f(x)$。

**问题的形式化**

监督学习分为学习和预测两个过程，由学习系统与预测系统完成。

![监督学习](images\1-1.png "监督学习")

首先给定一个训练数据集 $T = \{(x_1, y_1), (x_2, y_2), \cdots, (x_N, y_N)\}$ 
-  $(x_i, y_i),\ i=1,2,\dots,N$，称为样本或样本点
- $x_i \in \mathcal{X} \subseteq \mathbb{R}^n$ 是输入的观测值，也称为输入或实例
- $y_i \in \mathcal{Y}$ 是输出的观测值，也称为输出

在学习过程中，学习系统利用给定的训练数据集，通过学习（或训练）得到一个模型，表示为条件概率分布 $\hat{P}(Y|X)$ 或决策函数 $Y = \hat{f}(X)$。

- 条件概率分布 $\hat{P}(Y|X)$ 或决策函数 $Y = \hat{f}(X)$ 描述输入与输出随机变量之间的映射关系。

在预测过程中，预测系统对于给定的测试样本集中的输入 $x_{N+1}$，由模型 
$$
y_{N+1} = \arg\max_y \hat{P}(y|x_{N+1})$
$$
 或 
$$
\ y_{N+1} = \hat{f}(x_{N+1})
$$
给出相应的输出 $y_{N+1}$。

##### 无监督学习

**无监督学习 （unsupervised learning）** 是指从无标注数据中学习预测模型的机器学习问题。

无监督学习的本质是学习数据中的统计规律或潜在结构。

模型的输入与输出的所有可能取值的集合分别称为输入空间与输出空间。

假设 $\mathcal{X}$ 是输入空间，$\mathcal{Z}$ 是隐式结构空间。要学习的模型可以表示为函数 $z = g(x)$，条件概率分布 $P(z|x)$，或者条件概率分布 $P(x|z)$ 的形式，其中 $x \in \mathcal{X}$ 是输入，$z \in \mathcal{Z}$ 是输出。

无监督学习通常使用大量的无标注数据学习或训练，每一个样本是一个实例。训练数据表示为 $U = \{x_1, x_2, \dots, x_N\}$，其中 $x_i,\ i = 1, 2, \dots, N$，是样本。

无监督学习可以用于对已有数据的分析，也可以用于对未来数据的预测。

分析时使用学习得到的模型，即函数 $z = \hat{g}(x)$，条件概率分布 $\hat{P}(z|x)$，或者条件概率分布 $\hat{P}(x|z)$。

预测时由学习系统与预测系统完成
- 在学习过程中，学习系统从训练数据集学习，得到一个最优模型，表示为函数 $z = \hat{g}(x)$，条件概率分布 $\hat{P}(z|x)$ 或者条件概率分布 $\hat{P}(x|z)$。
- 在预测过程中，预测系统对于给定的输入 $x_{N+1}$，由模型 $z_{N+1} = \hat{g}(x_{N+1})$ 或 $z_{N+1} = \arg\max_z \hat{P}(z|x_{N+1})$ 给出相应的输出 $z_{N+1}$，进行聚类或降维，或者由模型 $\hat{P}(x|z)$ 给出输入的概率 $\hat{P}(x_{N+1}|z_{N+1})$，进行概率估计。

![无监督学习](images\1-2.png "无监督学习")

##### 强化学习

**强化学习 (reinforcement learning)** 是指智能系统在与环境的连续互动中学习最优行为策略的机器学习问题。

假设智能系统与环境的互动基于**马尔可夫决策过程 (Markov decision process)** ，智能系统能观测到的是与环境互动得到的数据序列。 

强化学习的本质是学习最优的序贯决策。

![智能系统与环境的互动](images\1-3.png "智能系统与环境的互动")



- 在每一步 $t$，智能系统从环境中观察到一个状态（state）$s_t$ 与一个奖励（reward）$r_t$，采取一个动作（action）$a_t$。
- 环境根据智能系统选择的动作，决定下一步 $t+1$ 的状态 $s_{t+1}$ 与奖励 $r_{t+1}$。要学习的策略表示为给定的状态下采取的动作。

智能系统的目标不是短期奖励的最大化，而是长期累计奖励的最大化。强化学习过程中，系统不断地试错（trial and error），以达到学习最优策略的目的。

**强化学习的马尔可夫决策过程**

强化学习的马尔可夫决策过程是状态、奖励、动作序列上的随机过程，由五元组 $\langle S, A, P, r, \gamma \rangle$ 组成。

- $S$ 是有限状态（state）的集合  
- $A$ 是有限动作（action）的集合  
- $P$ 是状态转移概率（transition probability）函数：
   
  $$
  P(s'|s,a) = P(s_{t+1} = s' | s_t = s, a_t = a)
  $$
  
- $r$ 是奖励函数（reward function）：$r(s,a) = \mathbb{E}(r_{t+1} | s_t = s, a_t = a)$  
- $\gamma$ 是衰减系数（discount factor）：$\gamma \in [0, 1]$

马尔可夫决策过程具有马尔可夫性，下一个状态只依赖于前一个状态与动作，由状态转移概率函数 $P(s'|s,a)$ 表示。下一个奖励依赖于前一个状态与动作，由奖励函数 $r(s,a)$ 表示。

策略 $\pi$ 定义为给定状态下动作的函数 $a = f(s)$ 或者条件概率分布 $P(a|s)$。给定一个策略 $\pi$，智能系统与环境互动的行为就已确定（或者是确定性的或者是随机性的）。

**价值函数（value function）**或状态价值函数（state value function）定义为策略 $\pi$ 从某一个状态 $s$ 开始的长期累积奖励的数学期望：
$$
v_\pi(s) = \mathbb{E}_\pi [r_{t+1} + \gamma r_{t+2} + \gamma^2 r_{t+3} + \cdots | s_t = s]
$$
**动作价值函数（action value function）**定义为策略 $\pi$ 的从某一个状态 $s$ 和动作 $a$ 开始的长期累积奖励的数学期望：
$$
q_\pi(s, a) = \mathbb{E}_\pi [r_{t+1} + \gamma r_{t+2} + \gamma^2 r_{t+3} + \cdots | s_t = s, a_t = a]
$$

强化学习的目标就是在所有可能的策略中选出价值函数数值最大的策略 $\pi^*$，而在实际学习中往往从具体的策略出发，不断优化已有策略。这里 $\gamma$ 表示未来的奖励会有衰减。

强化学习方法中

- 无模型的（model-free）方法

  - 基于策略的（policy-based）方法

    无模型的、基于策略的方法不直接学习模型，而是试图求解最优策略 $\pi^*$，表示为函数 $a = f^*(s)$ 或者是条件概率分布 $P^*(a|s)$。

  - 基于价值的（value-based）方法

    无模型的、基于价值的方法不直接学习模型，而是试图求解最优价值函数，特别是最优动作价值函数 $q^*(s, a)$。

- 有模型的（model-based）方法

  有模型的方法试图直接学习马尔可夫决策过程的模型，包括转移概率函数 $P(s'|s,a)$ 和奖励函数 $r(s,a)$。这样可以通过模型对环境的反馈进行预测，求出价值函数数值最大的策略 $\pi^*$。

有模型的方法试图直接学习马尔可夫决策过程的模型，包括转移概率函数 $P(s'|s,a)$ 和奖励函数 $r(s,a)$。这样可以通过模型对环境的反馈进行预测，求出价值函数数值最大的策略 $\pi^*$。

无模型的、基于策略的方法不直接学习模型，而是试图求解最优策略 $\pi^*$，表示为函数 $a = f^*(s)$ 或者是条件概率分布 $P^*(a|s)$，这样也能达到在环境中做出最优决策的目的。

##### 半监督学习与主动学习

**半监督学习 (semi-supervised learning)** 是指利用标注数据和未标注数据学习预测模型的机器学习问题。

半监督学习旨在利用未标注数据中的信息，辅助标注数据，进行监督学习，以较低的成本达到较好的学习效果。

**主动学习 (active learning)** 是指机器不断主动给出实例让教师进行标注，然后利用标注数据学习预测模型的机器学习问题。

主动学习的目标是找出对学习最有帮助的实例让教师标注，以较小的标注代价，达到较好的学习效果。

#### 按模型分类

##### 概率模型与非概率模型

统计学习的模型可以分为**概率模型（probabilistic model）**和**非概率模型（non-probabilistic model）**(确定性模型（deterministic model）)。

在监督学习中

- 概率模型是生成模型，非概率模型是判别模型。

- 概率模型取条件概率分布形式 $P(y|x)$

- 非概率模型取函数形式 $y = f(x)$

  其中 $x$ 是输入，$y$ 是输出。


在无监督学习中

- 概率模型取条件概率分布形式 $P(z|x)$ 或 $P(x|z)$

- 非概率模型取函数形式 $z = g(x)$

  其中 $x$ 是输入，$z$ 是输出。

条件概率分布 $P(y|x)$ 和函数 $y = f(x)$ 可以相互转化（条件概率分布 $P(z|x)$ 和函数 $z = g(x)$ 同样可以）

- 具体地，条件概率分布最大化后得到函数，函数归一化后得到条件概率分布。

##### 线性模型与非线性模型

统计学习模型，特别是非概率模型，可以分为**线性模型(linear model)** 和**非线性模型 (non-linear model)** 。

如果函数 $y = f(x)$ 或 $z = g(x)$ 是线性函数，则称模型是线性模型，否则称模型是非线性模型。

**参数化模型与非参数化模型**

统计学习模型又可以分为**参数化模型 (parametric model)**和**非参数化模型 (non parametric model)** 。

参数化模型假设模型参数的维度固定，模型可以由有限维参数完全刻画

非参数化模型假设模型参数的维度不固定或者说无穷大，随着训练数据量的增加而不断增大。

#### 按算法分类

##### 在线学习与批量学习

统计学习根据算法，可以分为**在线学习 (online learning)** 与**批量学习 (batch learning)** 。

在线学习是指每次接受一个样本，进行预测，之后学习模型，并不断重复该操作的机器学习。

批量学习一次接受所有数据，学习模型，之后进行预测。

**在线学习的过程**

学习和预测在一个系统

- 每次接受一个输入 $x_t$，用已有模型给出预测 $\hat{f}(x_t)$
- 得到相应的反馈，即该输入对应的输出 $y_t$
- 系统用损失函数计算两者的差异，更新模型
- 不断重复以上操作

#### 按技巧分类

##### 贝叶斯学习

**贝叶斯学习 (Bayesian learning)** ，又称为**贝叶斯推理 (Bayesian inference)** ，是统计学、机器学习中重要的方法。

其主要想法是：在概率模型的学习和推理中，利用贝叶斯定理，计算在给定数据条件下模型的条件概率，即后验概率，并应用这个原理进 行模型的估计，以及对数据的预测。

假设随机变量 $D$ 表示数据，随机变量 $\theta$ 表示模型参数。根据贝叶斯定理，可以用以下公式计算后验概率 $P(\theta|D)$：

$$
P(\theta|D) = \frac{P(\theta) P(D|\theta)}{P(D)}
$$

- 其中 $P(\theta)$ 是先验概率，$P(D|\theta)$ 是似然函数

模型估计时，估计整个后验概率分布 $P(\theta|D)$。如果需要给出一个模型，通常取后验概率最大的模型。

预测时，计算数据对后验概率分布的期望值：

$$
P(x|D) = \int P(x|\theta, D) P(\theta|D) \,\mathrm{d}\theta
$$

- 这里 $x$ 是新样本

![贝叶斯估计与极大似然估计](images\1-4.png "贝叶斯估计与极大似然估计")

假设先验分布是均匀分布，取后验概率最大，就能从贝叶斯估计得到极大似然估计。

##### 核方法

**核方法 (kernel method)** 是使用核函数表示和学习非线性模型的一种机器学习方法，可以用于监督学习和无监督学习。

把线性模型扩展到非线性模型，直接的做法是显式地定义从输入空间(低维空间) 到特征空间(高维空间)的映射，在特征空间中进行内积计算。核方法的技巧在于不显式地定义这个映射，而是直接定义核函数，即映射之后在特征空间的内积。

![输入空间到特征空间的映射](images\1-5.png "输入空间到特征空间的映射")

### 1.3 统计学习万法三要素

统计学习方法都是由模型、策略和算法构成的，即统计学习方法由三要素构成，可以简单地表示为：

$$
方法 = 模型 + 策略 + 算法
$$

#### 模型

在监督学习过程中，模型就是所要学习的条件概率分布或决策函数。模型的假设空间 (hypothesis space) 包含所有可能的条件概率分布或决策函数。

假设空间用 $\mathcal{F}$ 表示。

**假设空间可以定义为决策函数的集合：**
$$
\mathcal{F} = \{f \mid Y = f(X)\}
$$

- $X$ 和 $Y$ 是定义在输入空间 $\mathcal{X}$ 和输出空间 $\mathcal{Y}$ 上的变量

这时$\mathcal{F}$ 通常是由一个参数向量决定的函数族：
$$
\mathcal{F} = \{f \mid Y = f_\theta(X),\ \theta \in \mathbb{R}^n\}
$$

- 参数向量 $\theta$ 取值于 $n$ 维欧氏空间 $\mathbb{R}^n$，称为**参数空间（parameter space）**

**假设空间也可以定义为条件概率的集合：**
$$
\mathcal{F} = \{P \mid P(Y|X)\}
$$

- $X$ 和 $Y$ 是定义在输入空间 $\mathcal{X}$ 和输出空间 $\mathcal{Y}$ 上的随机变量

这时 $\mathcal{F}$ 通常是由一个参数向量决定的条件概率分布族：
$$
\mathcal{F} = \{P \mid P_\theta(Y|X),\ \theta \in \mathbb{R}^n\}
$$

- 参数向量 $\theta$ 取值于 $n$ 维欧氏空间 $\mathbb{R}^n$，也称为参数空间。

#### 策略

##### 损失函数和风险函数

损失函数是 $f(X)$ 和 $Y$ 的非负实值函数，记作 $L(Y，f(X))$。

**损失函数(Loss function)** 或**代价函数 (cost function)** 来度量预测错误的程度。



**0-1 损失函数（0-1 loss function）**
$$
L(Y, f(X)) = 
\begin{cases}
1, & Y \ne f(X) \\
0, & Y = f(X)
\end{cases}
$$

**平方损失函数（quadratic loss function）**
$$
L(Y, f(X)) = (Y - f(X))^2
$$
**绝对损失函数（absolute loss function）**
$$
L(Y, f(X)) = |Y - f(X)|
$$

**对数损失函数（logarithmic loss function）**或 **对数似然损失函数（log-likelihood loss function）**
$$
L(Y, P(Y|X)) = -\log P(Y|X)
$$

由于模型的输入、输出 $(X, Y)$ 是随机变量，遵循联合分布 $P(X, Y)$，所以损失函数的期望是

$$
R_{\text{exp}}(f) = \mathbb{E}_P[L(Y, f(X))] \\
= \int_{\mathcal{X} \times \mathcal{Y}} L(y, f(x)) P(x, y) \, dx \, dy
$$

这是理论上模型 $f(X)$ 关于联合分布 $P(X, Y)$ 的平均意义下的损失，称为**风险函数（risk function）**或**期望损失（expected loss）**。



给定一个训练数据集
$$
T = \{(x_1, y_1), (x_2, y_2), \cdots, (x_N, y_N)\}
$$

模型 $f(X)$ 关于训练数据集的平均损失称为**经验风险（empirical risk）**或**经验损失（empirical loss）**，记作 $R_{\text{emp}}$：

$$
R_{\text{emp}}(f) = \frac{1}{N} \sum_{i=1}^{N} L(y_i, f(x_i))
$$

期望风险 $R_{\text{exp}}(f)$ 是模型关于联合分布的期望损失，经验风险 $R_{\text{emp}}(f)$ 是模型关于训练样本集的平均损失。

##### 经验风险最小化与结何风险最小化

**经验风险最小化（empirical risk minimization，ERM）**的策略认为，经验风险最小的模型是最优的模型。根据这一策略，按照经验风险最小化求最优模型就是求解最优化问题：
$$
\min_{f \in \mathcal{F}} \frac{1}{N} \sum_{i=1}^{N} L(y_i, f(x_i))
$$

- 其中，$\mathcal{F}$ 是假设空间

但是，当样本容量很小时，经验风险最小化学习的效果就未必很好，会产生“过拟合”（over-fitting）现象。

**结构风险最小化（structural risk minimization，SRM）**是为了防止过拟合而提出的策略。结构风险最小化等价于**正则化（regularization）**。

结构风险在经验风险上加上表示模型复杂度的**正则化项（regularizer）**或 **罚项（penalty term）**。

在假设空间、损失函数以及训练数据集确定的情况下，结构风险的定义是：
$$
R_{\text{srm}}(f) = \frac{1}{N} \sum_{i=1}^{N} L(y_i, f(x_i)) + \lambda J(f)
$$

- 其中 $J(f)$ 为模型的复杂度，是定义在假设空间 $\mathcal{F}$ 上的泛函。模型 $f$ 越复杂，复杂度 $J(f)$ 就越大；反之，模型 $f$ 越简单，复杂度 $J(f)$ 就越小。
- $\lambda > 0$ 是系数，用以权衡经验风险和模型复杂度。结构风险小需要经验风险与模型复杂度同时小。结构风险小的模型往往对训练数据以及未知的测试数据都有较好的预测。

比如，贝叶斯估计中的**最大后验概率估计（maximum posterior probability estimation，MAP）**就是结构风险最小化的一个例子。当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时，结构风险最小化就等价于最大后验概率估计。

结构风险最小化的策略认为结构风险最小的模型是最优的模型。所以求最优模型，就是求解最优化问题：

$$
\min_{f \in \mathcal{F}} \frac{1}{N} \sum_{i=1}^{N} L(y_i, f(x_i)) + \lambda J(f)
$$

#### 算法

算法是指学习模型的具体计算方法。

### 1.4 模型评估与模型选择

#### 训练误差与测试误差

**训练误差**

训练误差是模型 $Y = \hat{f}(X)$ 关于训练数据集的平均损失：
$$
R_{\text{emp}}(\hat{f}) = \frac{1}{N} \sum_{i=1}^{N} L(y_i, \hat{f}(x_i))
$$

- 其中 $N$ 是训练样本容量

**测试误差**

测试误差是模型 $Y = \hat{f}(X)$ 关于测试数据集的平均损失：

$$
e_{\text{test}} = \frac{1}{N'} \sum_{i=1}^{N'} L(y_i, \hat{f}(x_i))
$$

- 其中 $N'$ 是测试样本容量

**误差率**

当损失函数是 0-1 损失时，测试误差就变成了常见的测试数据集上的**误差率（error rate）**：

$$
e_{\text{test}} = \frac{1}{N'} \sum_{i=1}^{N'} I(y_i \ne \hat{f}(x_i))
$$

- 这里 $I$ 是**指示函数（indicator function）**，即 $y \ne \hat{f}(x)$ 时为 1，否则为 0

**准确率**

相应地，常见的测试数据集上的**准确率（accuracy）**为：

$$
r_{\text{test}} = \frac{1}{N'} \sum_{i=1}^{N'} I(y_i = \hat{f}(x_i))
$$

显然，

$$
r_{\text{test}} + e_{\text{test}} = 1
$$
对未知数据的预测能力称为**泛化能力 (generalization  ability)** 。

#### 过拟合与模型选择

**过拟合 (over-fitting)** 是指学习时选择的模型所包含的参数过多，以至出现这一模型对己知数据预测得很好，但对未知数据预测得很差的现象。

**M次多项式函数过拟合**

对于给定的数据集
$$
T =  \{(x_1,y_1),(x_2,y_2),\dots,(x_N,y_N)\}
$$

- 其中，$x_i \in \mathbb{R}$ 是输入 $x$ 的观测值，$y_i \in \mathbb{R}$ 是相应的输出 $y$ 的观测值，$i = 1, 2, \dots, N$

多项式函数拟合的任务是假设给定数据由 $M$ 次多项式函数生成，选择最有可能产生这些数据的 $M$ 次多项式函数。

![M 次多项式函数拟合问题的例子](images\1-6.png "M 次多项式函数拟合问题的例子")

设 $M$ 次多项式为
$$
f_M(x, w) = w_0 + w_1 x + w_2 x^2 + \cdots + w_M x^M = \sum_{j=0}^{M} w_j x^j
$$

- 其中 $x$ 是单变量输入，$w_0, w_1, \dots, w_M$ 是 $M+1$ 个参数

首先确定模型的复杂度，即确定多项式的次数；然后在给定的模型复杂度下，按照经验风险最小化的策略，求解参数，即多项式的系数。具体地，求以下经验风险最小化：

$$
L(w) = \frac{1}{2} \sum_{i=1}^{N} (f(x_i, w) - y_i)^2
$$

- 这时，损失函数为平方损失，系数 $\frac{1}{2}$ 是为了计算方便

这是一个简单的最优化问题。将模型与训练数据代入上式中，有

$$
L(w) = \frac{1}{2} \sum_{i=1}^{N} \left( \sum_{j=0}^{M} w_j x_i^j - y_i \right)^2
$$

最后可用最小二乘法求得拟合多项式系数的唯一解，记作 $w_0^*, w_1^*, \dots, w_M^*$。

当 $M=1$ 时，多项式曲线是一条直线，数据拟合效果很差。

当 $M=9$ 时，多项式曲线通过每个数据点，训练误差为0。但与实际的模型相差很大，预测效果不好。

当 $M=3$ 时，多项式曲线对训 练数据拟合效果足够好，模型也比较简单，是一个较好的选择。

![训练误差和测试误差与模型复杂度的关系](images\1-7.png "训练误差和测试误差与模型复杂度的关系")

当模型的复杂度增大时，训练误差会逐渐减小井趋向于0; 而测试误差会先减小，达到最小值后又增大。当选择的模型复杂度过大时，过拟合现象就会发生。

### 1.5 正则化与交叉验证

#### 正则化

模型选择的典型方法是**正则化 (regularization)** 。正则化是结构风险最小化策略 的实现，是在经验风险上加一个**正则化项 (regularizer)** 或**罚项 (penalty term)** 。正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。

正则化一般具有如下形式：

$$
\min_{f \in \mathcal{F}} \frac{1}{N} \sum_{i=1}^{N} L(y_i, f(x_i)) + \lambda J(f)
$$

- 第 1 项是经验风险，第 2 项是正则化项
- $\lambda \geq 0$ 为调整两者之间关系的系数

正则化项可以取不同的形式。

回归问题中，损失函数是平方损失，那么

- 正则化项可以是参数向量的 $L_2$ 范数：

$$
L(w) = \frac{1}{N} \sum_{i=1}^{N} (f(x_i; w) - y_i)^2 + \frac{\lambda}{2} \|w\|^2
$$

​	这里，$\|w\|$ 表示参数向量 $w$ 的 $L_2$ 范数。

- 正则化项也可以是参数向量的 $L_1$ 范数：

$$
L(w) = \frac{1}{N} \sum_{i=1}^{N} (f(x_i; w) - y_i)^2 + \lambda \|w\|_1
$$

​	这里，$\|w\|_1$ 表示参数向量 $w$ 的 $L_1$ 范数。

#### 交叉验证

##### 简单交叉验证

首先随机地将已给数据分为两部分，一部分作为训练集，另一部分作为测试集（例如，70% 的数据为训练集，30% 的数据为测试集）；然后用训练集在各种条件下（例如，不同的参数个数）训练模型，从而得到不同的模型；在测试集上评价各个模型的测试误差，选出测试误差最小的模型。

##### $S$ 折交叉验证

应用最多的是 **$S$ 折交叉验证（$S$-fold cross validation）**，方法如下：首先随机地将已给数据切分为 $S$ 个互不相交、大小相同的子集；然后利用 $S-1$ 个子集的数据训练模型，利用余下的子集测试模型；将这一过程对可能的 $S$ 种选择重复进行；最后选出 $S$ 次评测中平均测试误差最小的模型。

##### 留一交叉验证

$S$ 折交叉验证的特殊情形是 $S=N$，称为**留一交叉验证（leave-one-out cross validation）**，往往在数据缺乏的情况下使用。这里，$N$ 是给定数据集的容量。

### 1.6 泛化能力

#### 泛化误差

如果学到的模型是 $\hat{f}$，那么用这个模型对未知数据预测的误差即为**泛化误差（generalization error）**：

$$
R_{\text{exp}}(\hat{f}) = \mathbb{E}_P[L(Y, \hat{f}(X))] \\
= \int_{\mathcal{X} \times \mathcal{Y}} L(y, \hat{f}(x)) P(x, y) \, dx \, dy
$$
泛化误差越小，学习方法越有效。

#### 泛化误差上界

学习方法的泛化能力分析往往是通过研究泛化误差的概率上界进行的，简称为泛化误差上界 (generalization error bound)。

样本容量增加时，泛化上界趋于0；假设空间容量越大，泛化误差上界就越大。

**二类分类问题的泛化误差上界**

已知训练数据集
$$
T = \{(x_1, y_1), (x_2, y_2), \cdots, (x_N, y_N)\}
$$

- $N$ 是样本容量
- $T$ 是从联合概率分布 $P(X, Y)$ 独立同分布产生的
- $X \in \mathbb{R}^n, Y \in \{-1, +1\}$

假设空间是函数的有限集合 $\mathcal{F} = \{f_1, f_2, \cdots, f_d\}$，$d$ 是函数个数。

- 设 $f$ 是从 $\mathcal{F}$ 中选取的函数
- 损失函数是 0-1 损失

关于 $f$ 的期望风险和经验风险分别是：
$$
R(f) = \mathbb{E}[L(Y, f(X))]
$$

$$
\hat{R}(f) = \frac{1}{N} \sum_{i=1}^{N} L(y_i, f(x_i))
$$

经验风险最小化函数是：

$$
f_N = \arg\min_{f \in \mathcal{F}} \hat{R}(f)
$$

$f_N$ 依赖训练数据集的样本容量 $N$。 $f_N$ 的泛化能力表示为：

$$
R(f_N) = \mathbb{E}[L(Y, f_N(X))]
$$

##### 定理 1.1（泛化误差上界）

对二类分类问题，当假设空间是有限个函数的集合 $\mathcal{F} = \{f_1, f_2, \cdots, f_d\}$ 时，对任意一个函数 $f \in \mathcal{F}$，至少以概率 $1 - \delta$，$0 < \delta < 1$，以下不等式成立：
$$
R(f) \leq \hat{R}(f) + \varepsilon(d, N, \delta)
$$

其中，

$$
\varepsilon(d, N, \delta) = \sqrt{\frac{1}{2N} \left( \log d + \log \frac{1}{\delta} \right)}
$$

- 不等式左端 $R(f)$ 是泛化误差，右端即为泛化误差上界。
- 在泛化误差上界中
  - 第 1 项是训练误差，训练误差越小，泛化误差也越小。
  - 第 2 项 $\varepsilon(d, N, \delta)$ 是 $N$ 的单调递减函数，当 $N$ 趋于无穷时趋于 0；同时它也是 $\sqrt{\log d}$ 阶的函数，假设空间 $\mathcal{F}$ 包含的函数越多，其值越大。

### 1.7 生成模型与判别模型

监督学习的任务就是学习一个模型，应用这一模型，对给定的输入预测相应的输出。

这个模型的一般形式为

- 决策函数：$ Y=f(x) $
- 条件分布概率：$P(Y|X)$

监督学习方法又可以分为**生成方法 (generative approach)**和**判别方法 (discriminative approach)**。所学到的模型分别称为**生成模型(generative model)** 和**判别模型 (discriminative model)**。

#### 生成方法

由数据学习联合概率分布 $P(X, Y)$，然后求出条件概率分布 $P(Y|X)$ 作为预测的模型，即生成模型：
$$
P(Y|X) = \frac{P(X, Y)}{P(X)}
$$

这样的方法之所以称为生成方法，是因为模型表示了给定输入 $X$ 产生输出 $Y$ 的生成关系。

优点：

- 生成方法可以还原出联合概率分布 $P(X, Y)$，而判别方法则不行
- 生成方法的学习收敛速度更快，即当样本容量增加的时候，学到的模型可以更快地收敛于真实模型
- 当存在隐变量时，仍可以用生成方法学习，此时判别方法就不适用了

#### 判别方法

判别方法由数据直接学习决策函数 $f(X)$ 或者条件概率分布 $P(Y|X)$ 作为预测的模型，即判别模型。判别方法关心的是对给定的输入 $X$，应该预测什么样的输出 $Y$。

优点：

- 判别方法直接学习的是条件概率 $P(Y|X)$ 或决策函数 $f(X)$，直接面对预测，往往学习的准确率更高

- 对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题

### 1.8 监督学习应用

#### 分类问题

监督学习从数据中学习一个分类模型或分类决策函数，称为**分类器(classifier)**。 分类器对新的输入进行输出的预测，称为**分类 (classification)** 。可能的输出称为**类别 (class)** 。

![分类问题](images\1-8.png "分类问题")

**分类准确率(accuracy)**：对于给定的测试数据集，分类器正确分类的样本数与总样本数之比。也就是损失函数是0-1损失时测试数据集上的准确率。

- TP —— 将正类预测为正类数
- FN —— 将正类预测为负类数
- FP —— 将负类预测为正类数 
- TN —— 将负类预测为负类数

**精确率 (precision)**：
$$
P = \frac{\text{TP}}{\text{TP} + \text{FP}}
$$

**召回率 (recall)**：
$$
R = \frac{\text{TP}}{\text{TP} + \text{FN}}
$$

 **$F_1$ 值**：精确率和召回率的调和均值，即

$$
\frac{2}{F_1} = \frac{1}{P} + \frac{1}{R}
$$

$$
F_1 = \frac{2\text{TP}}{2\text{TP} + \text{FP} + \text{FN}}
$$

#### 标注问题

**标注 (tagging)** 也是一个监督学习问题。可以认为标注问题是分类问题的一个推广，标注问题又是更复杂的结构预测 (structure prediction) 问题的简单形式。

标注问题的目标在于学习一个模型，使它能够对观测序列给出标记序列作为预测。

标注问题分为学习和标注两个过程。



首先给定一个训练数据集
$$
T = \{(x_1, y_1), (x_2, y_2), \cdots, (x_N, y_N)\}
$$

- $x_i = (x_i^{(1)}, x_i^{(2)}, \cdots, x_i^{(n)})^\mathrm{T}$，$i = 1, 2, \cdots, N$，是输入观测序列

-  $y_i = (y_i^{(1)}, y_i^{(2)}, \cdots, y_i^{(n)})^\mathrm{T}$ 是相应的输出标记序列
- $n$ 是序列的长度，对不同样本可以有不同的值

学习系统基于训练数据集构建一个模型，表示为条件概率分布：
$$
P(Y^{(1)}, Y^{(2)}, \cdots, Y^{(n)} \mid X^{(1)}, X^{(2)}, \cdots, X^{(n)})
$$

- 每一个 $X^{(i)}$（$i = 1, 2, \cdots, n$）取值为所有可能的观测
- 每一个 $Y^{(i)}$（$i = 1, 2, \cdots, n$）取值为所有可能的标记
- 一般 $n \ll N$

标注系统按照学习得到的条件概率分布模型，对新的输入观测序列找到相应的输出标记序列。

具体地，对一个观测序列
$$
x_{N+1} = (x_{N+1}^{(1)}, x_{N+1}^{(2)}, \cdots, x_{N+1}^{(n)})^\mathrm{T}
$$

找到使条件概率

$$
P((y_{N+1}^{(1)}, y_{N+1}^{(2)}, \cdots, y_{N+1}^{(n)})^\mathrm{T} \mid (x_{N+1}^{(1)}, x_{N+1}^{(2)}, \cdots, x_{N+1}^{(n)})^\mathrm{T})
$$

最大的标记序列

$$
y_{N+1} = (y_{N+1}^{(1)}, y_{N+1}^{(2)}, \cdots, y_{N+1}^{(n)})^\mathrm{T}
$$
![标注问题](images\1-9.png "标注问题")

#### 回归问题

**回归（regression）**用于预测输入变量（自变量）和输出变量（因变量）之间的关系，特别是当输入变量的值发生变化时，输出变量的值随之发生的变化。

回归问题分为学习和预测两个过程。

首先给定一个训练数据集：
$$
T = \{(x_1, y_1), (x_2, y_2), \cdots, (x_N, y_N)\}
$$

- 这里，$x_i \in \mathbb{R}^n$ 是输入，$y \in \mathbb{R}$ 是对应的输出，$i = 1, 2, \cdots, N$

学习系统基于训练数据构建一个模型，即函数 $Y = f(X)$；对新的输入 $x_{N+1}$，预测系统根据学习的模型 $Y = f(X)$ 确定相应的输出 $y_{N+1}$。

![回归问题](images\1-10.png "回归问题")

回归学习最常用的损失函数是平方损失函数，在此情况下，回归问题可以由著名的**最小二乘法 (least squares)** 求解。

## 第二章 感知机

### 2.1 感知机模型

##### 定义 2.1（感知机）

假设输入空间（特征空间）是 $\mathcal{X} \subseteq \mathbb{R}^n$，输出空间是 $\mathcal{Y} = \{+1, -1\}$。输入 $x \in \mathcal{X}$ 表示实例的特征向量，对应于输入空间（特征空间）的一点；输出 $y \in \mathcal{Y}$ 表示实例的类别。由输入空间到输出空间的如下函数称为感知机。：
$$
f(x) = \mathrm{sign}(w \cdot x + b)
$$

- 其中，$w$ 和 $b$ 为感知机模型参数，$w \in \mathbb{R}^n$ 叫作权值（weight）或权值向量（weight vector），$b \in \mathbb{R}$ 叫作偏置（bias），$w \cdot x$ 表示 $w$ 和 $x$ 的内积
- sign 是符号函数，即：

$$
\mathrm{sign}(x) = 
\begin{cases}
+1, & x \geq 0 \\
-1, & x < 0
\end{cases}
$$

![感知机模型](images\2-1.png "感知机模型")

感知机有如下几何解释：

$$
w \cdot x + b = 0
$$

- 以上线性方程对应于特征空间 $\mathbf{R}^n$ 中的一个超平面 $S$，其中 $w$ 是超平面的法向量，$b$ 是超平面的截距。

这个超平面将特征空间划分为两个部分。位于两部分的点（特征向量）分别被分为正、负两类。因此，超平面 $S$ 称为**分离超平面（separating hyperplane）**。

### 2.2 感知机学习策略

#### 数据集的线性可分性

##### **定义 2.2（数据集的线性可分性）** 

给定一个数据集
$$
T = \{(x_1, y_1), (x_2, y_2), \cdots, (x_N, y_N)\}
$$

其中，$x_i \in \mathcal{X} = \mathbf{R}^n$，$y_i \in \mathcal{Y} = \{+1, -1\}$，$i = 1, 2, \cdots, N$，如果存在某个超平面 $S$

$$
w \cdot x + b = 0
$$

能够将数据集的正实例点和负实例点完全正确地划分到超平面的两侧，即对所有 $y_i = +1$ 的实例 $i$，有 $w \cdot x_i + b > 0$，对所有 $y_i = -1$ 的实例 $i$，有 $w \cdot x_i + b < 0$，则称数据集 $T$ 为**线性可分数据集**（linearly separable data set）；否则，称数据集 $T$ **线性不可分**。

#### 感知机学习策略

给定训练数据集

$$
T = \{(x_1, y_1), (x_2, y_2), \cdots, (x_N, y_N)\}
$$

- 其中，$x_i \in \mathcal{X} = \mathbf{R}^n$，$y_i \in \mathcal{Y} = \{+1, -1\}$，$i = 1, 2, \cdots, N$。

感知机 $\operatorname{sign}(w \cdot x + b)$ 学习的损失函数定义为
$$
L(w, b) = - \sum_{x_i \in M} y_i (w \cdot x_i + b)
$$

- 其中 $M$ 为误分类点的集合。

这个损失函数就是感知机学习的经验风险函数。

感知机损失函数与误分类点到超平面的距离有关，误分类点越少，误分类点离超平面越近，损失函数值就越小。

### 2.3  感知机学习算法

#### 感知机学习算法的原始形式

感知机学习算法是对以下最优化问题的算法。给定一个训练数据集

$$
T = \{(x_1, y_1), (x_2, y_2), \cdots, (x_N, y_N)\}
$$

- 其中，$x_i \in \mathcal{X} = \mathbf{R}^n$，$y_i \in \mathcal{Y} = \{-1, 1\}$，$i = 1, 2, \cdots, N$

求参数 $w, b$，使其为以下损失函数极小化问题的解
$$
\min_{w, b} L(w, b) = - \sum_{x_i \in M} y_i (w \cdot x_i + b)
$$

- 其中 $M$ 为误分类点的集合

感知机学习算法是误分类驱动的，具体采用**随机梯度下降法（stochastic gradient descent）**。

##### 算法 2.1（感知机学习算法的原始形式）

**输入：** 训练数据集  
$$
T = \{(x_1, y_1), (x_2, y_2), \cdots, (x_N, y_N)\}
$$
- 其中 $x_i \in \mathcal{X} = \mathbf{R}^n$，$y_i \in \mathcal{Y} = \{-1, +1\}$，$i = 1, 2, \cdots, N$
- 学习率 $\eta$（$0 < \eta \leq 1$）

**输出：** $w, b$；感知机模型 $f(x) = \operatorname{sign}(w \cdot x + b)$。

1. 选取初值 $w_0, b_0$；

2. 在训练集中选取数据 $(x_i, y_i)$；

3. 如果 $y_i(w \cdot x_i + b) \leq 0$，
   $$
   w \leftarrow w + \eta y_i x_i
   $$
   $$
   b \leftarrow b + \eta y_i
   $$

   式中 $\eta$ ($0 < \eta \leq 1$) 是步长，在统计学习中又称为**学习率（learning rate）**

4. 转至（2），直至训练集中没有误分类点。

**直观解释**：

当一个实例点被误分类，即位于分离超平面的错误一侧时，则调整 $w, b$ 的值，使分离超平面向该误分类点的一侧移动，以减少该误分类点与超平面间的距离，直至超平面越过该误分类点使其被正确分类。

#### 算法的收敛性

##### 定理 2.1（Novikoff） 

设训练数据集  
$$
T = \{(x_1, y_1), (x_2, y_2), \cdots, (x_N, y_N)\}
$$
是线性可分的，其中 $x_i \in \mathcal{X} = \mathbf{R}^n$，$y_i \in \mathcal{Y} = \{-1, +1\}$，$i = 1, 2, \cdots, N$，则

1. 存在满足条件 $\|\hat{w}_{\text{opt}}\| = 1$ 的超平面 $\hat{w}_{\text{opt}} \cdot \hat{x} = w_{\text{opt}} \cdot x + b_{\text{opt}} = 0$ 将训练数据集完全正确分开；且存在 $\gamma > 0$，对所有 $i = 1, 2, \cdots, N$

$$
y_i (\hat{w}_{\text{opt}} \cdot \hat{x}_i) = y_i (w_{\text{opt}} \cdot x_i + b_{\text{opt}}) \geq \gamma
$$

- 其中 $\hat{w} = (w^\mathrm{T}, b)^\mathrm{T}$， $\hat{x} = (x^\mathrm{T}, 1)^\mathrm{T}$，显然有 $\hat{w} \cdot \hat{x} = w \cdot x + b$

2. 令  $R = \max_{1 \leq i \leq N} \|\hat{x}_i\|$，则感知机算法 2.1 在训练数据集上的误分类次数 $k$ 满足不等式

$$
k \leq \left( \frac{R}{\gamma} \right)^2
$$

定理表明，误分类的次数k是有上界的，经过有限次搜索可以找到将训练数据完全正确分开的分离超平面。也就是说，当训练数据集线性可分时，感知机学习算法原始形式迭代是收敛的。

#### 感知机学习算法的对偶形式

对偶形式的基本想法是，将 $w$ 和 $b$ 表示为实例 $x_i$ 和标记 $y_i$ 的线性组合的形式， 通过求解其系数而求得 $w$ 和 $b$ 。 

**算法 2.2（感知机学习算法的对偶形式）**

**输入：** 线性可分的数据集  
$$
T = \{(x_1, y_1), (x_2, y_2), \cdots, (x_N, y_N)\}
$$
- 其中 $x_i \in \mathbf{R}^n$，$y_i \in \{-1, +1\}$，$i = 1, 2, \cdots, N$
- 学习率 $\eta$（$0 < \eta \leq 1$）

**输出：** $\alpha, b$；感知机模型  
$$
f(x) = \operatorname{sign} \left( \sum_{j=1}^{N} \alpha_j y_j x_j \cdot x + b \right),
$$
- 其中 $\alpha = (\alpha_1, \alpha_2, \cdots, \alpha_N)^\mathrm{T}$
- $b = \sum_{i=1}^{N} \alpha_i y_i$

1. $\alpha \leftarrow 0, \quad b \leftarrow 0$；
2. 在训练集中选取数据 $(x_i, y_i)$；
3. 如果  
   $$
   y_i \left( \sum_{j=1}^{N} \alpha_j y_j x_j \cdot x_i + b \right) \leq 0,
   $$
   则  
   $$
   \alpha_i \leftarrow \alpha_i + \eta
   $$
   $$
   b \leftarrow b + \eta y_i
   $$

4. 转至（2），直到没有误分类数据。

对偶形式中训练实例仅以内积的形式出现。为了方便，可以预先将训练集中实例间的内积计算出来并以矩阵的形式存储，这个矩阵就是所谓的 **Gram 矩阵（Gram matrix）**

$$
G = [x_i \cdot x_j]_{N \times N}
$$
